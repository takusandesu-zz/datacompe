{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "atema11.ipynb",
      "provenance": [],
      "mount_file_id": "1u020ebvaRVmXGCqW-XWV4HhXbOOXB06D",
      "authorship_tag": "ABX9TyPXlXbYJDKevP1Su411fxDc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takusandesu/kaggle/blob/main/atema11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK98FU7SoBPM"
      },
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from glob import  glob\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks2jHIL5S1xx"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from torch.utils import data\n",
        "\n",
        "# torchvision\n",
        "from torchvision import transforms as T\n",
        "from torchvision.models import resnet34\n",
        "\n",
        "# scikit-learn\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krxnUPMbo8OU",
        "outputId": "8620ea3f-356a-4c91-d363-d83e8a412899"
      },
      "source": [
        "!pip install python-vivid"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-vivid\n",
            "  Downloading python_vivid-0.3.3.4-py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from python-vivid) (0.22.2.post1)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (from python-vivid) (2.2.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from python-vivid) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from python-vivid) (2.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from python-vivid) (4.62.2)\n",
            "Requirement already satisfied: feather-format in /usr/local/lib/python3.7/dist-packages (from python-vivid) (0.4.1)\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.9.1-py3-none-any.whl (302 kB)\n",
            "\u001b[K     |████████████████████████████████| 302 kB 9.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from python-vivid) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from python-vivid) (1.19.5)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (from python-vivid) (0.90)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from python-vivid) (0.11.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from python-vivid) (0.8.9)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from python-vivid) (1.1.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from python-vivid) (1.0.1)\n",
            "Requirement already satisfied: pyarrow>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from feather-format->python-vivid) (3.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->python-vivid) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->python-vivid) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->python-vivid) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->python-vivid) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->python-vivid) (1.15.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.4.1-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna->python-vivid) (21.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna->python-vivid) (1.4.23)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.3-py3-none-any.whl (208 kB)\n",
            "\u001b[K     |████████████████████████████████| 208 kB 37.4 MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "  Downloading cliff-3.9.0-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna->python-vivid) (3.13)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna->python-vivid) (4.8.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna->python-vivid) (1.1.1)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.5-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna->python-vivid) (5.2.2)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 49.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->python-vivid) (2.2.0)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.4.0-py3-none-any.whl (20 kB)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.4.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.2.0-py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 49.7 MB/s \n",
            "\u001b[?25hCollecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->python-vivid) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->python-vivid) (21.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->python-vivid) (3.7.4.3)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna->python-vivid) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna->python-vivid) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->python-vivid) (2018.9)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=7f0ed8aa7dc366a450688a24d65facce726b8792aa0365616968f2663ecbef69\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, colorama, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna, python-vivid\n",
            "Successfully installed Mako-1.1.5 alembic-1.7.3 autopage-0.4.0 cliff-3.9.0 cmaes-0.8.2 cmd2-2.2.0 colorama-0.4.4 colorlog-6.4.1 optuna-2.9.1 pbr-5.6.0 pyperclip-1.8.2 python-vivid-0.3.3.4 stevedore-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQTYzE9gRqSh"
      },
      "source": [
        "### データの読み込みと画像ディレクトリのパス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9fxbx-eQId3"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/atmaCup11/inputs/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/atmaCup11/inputs/test.csv\")\n",
        "\n",
        "dataset_root = '/content/drive/MyDrive/atmaCup11/'\n",
        "\n",
        "input_dir = os.path.join(dataset_root, \"inputs\")\n",
        "photo_dir = os.path.join(input_dir, \"photos\")\n",
        "\n",
        "output_dir = os.path.join(dataset_root, \"outputs_tutorial#1__simple\")\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2gDFi7YRdwcl",
        "outputId": "cda8dd20-23cb-462c-ecc4-38a18aeeea25"
      },
      "source": [
        "photo_dir"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/atmaCup11/inputs/photos'"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEFsJnI5RacC",
        "outputId": "ea45e4f7-93df-412b-d2a6-df442e5b5147"
      },
      "source": [
        "glob('/content/drive/MyDrive/atmaCup11/inputs/*')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/atmaCup11/inputs/techniques.csv',\n",
              " '/content/drive/MyDrive/atmaCup11/inputs/test.csv',\n",
              " '/content/drive/MyDrive/atmaCup11/inputs/train.csv',\n",
              " '/content/drive/MyDrive/atmaCup11/inputs/atmaCup#11_sample_submission.csv',\n",
              " '/content/drive/MyDrive/atmaCup11/inputs/materials.csv',\n",
              " '/content/drive/MyDrive/atmaCup11/inputs/photos.zip',\n",
              " '/content/drive/MyDrive/atmaCup11/inputs/photos',\n",
              " '/content/drive/MyDrive/atmaCup11/inputs/data.zip']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "XWX20tcHQWi9",
        "outputId": "366d34f4-4d62-496e-f828-7cded4871413"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>object_id</th>\n",
              "      <th>sorting_date</th>\n",
              "      <th>art_series_id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>002bff09b09998d0be65</td>\n",
              "      <td>1631</td>\n",
              "      <td>509357f67692a6a45626</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00309fb1ef05416f9c1f</td>\n",
              "      <td>1900</td>\n",
              "      <td>7987b47bbe5dc3039179</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>003a1562e97f79ba96dc</td>\n",
              "      <td>1834</td>\n",
              "      <td>ded7c3c9636708e5b14c</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>004890880e8e7431147b</td>\n",
              "      <td>1743</td>\n",
              "      <td>582ac2d7f0cef195b605</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00718c32602425f504c1</td>\n",
              "      <td>1885</td>\n",
              "      <td>64c907f0c08dce4fb8e8</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              object_id  sorting_date         art_series_id  target\n",
              "0  002bff09b09998d0be65          1631  509357f67692a6a45626       1\n",
              "1  00309fb1ef05416f9c1f          1900  7987b47bbe5dc3039179       3\n",
              "2  003a1562e97f79ba96dc          1834  ded7c3c9636708e5b14c       3\n",
              "3  004890880e8e7431147b          1743  582ac2d7f0cef195b605       2\n",
              "4  00718c32602425f504c1          1885  64c907f0c08dce4fb8e8       3"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWrQDz_trYqc"
      },
      "source": [
        "### バリデーションの回数とエポック数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14mf9DqErF_E"
      },
      "source": [
        "N_FOLDS = 5\n",
        "N_EPOCHS = 1"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3m8Z3Xqb3Fl"
      },
      "source": [
        "### object_idから画像のパスを返す関数と画像を開く関数(to_img_path,read_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLGzNkzMsBPa"
      },
      "source": [
        "- `to_img_path`でobject_idを渡して、画像のパスを返す\n",
        "- object_idを渡して、画像を開く"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIBS115Qrnj2"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "def to_img_path(object_id):\n",
        "    return os.path.join(photo_dir, f'{object_id}.jpg')#photoの名前がobject_id.jpgになっている\n",
        "    #画像の相対パス\n",
        "def read_image(object_id):\n",
        "    return Image.open(to_img_path(object_id))#画像のパス"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK85fFj7TJ1p"
      },
      "source": [
        "### 処理の流れ\n",
        "1. trainデータのobject_idを画像へのパスに変換してtrainデータ(object_id,object_patah,target)を作る\n",
        "  - create_metadata(input_df)\n",
        "2. trainデータをtrain(学習用)とval(検証用)にk-foldで分割\n",
        "3. 使用するモデルを定義する(resnet34)\n",
        "  - create_model()\n",
        "4. trainとvalをミニバッチ化してtrainで学習し、valで検証する\n",
        "   - run_fold(\n",
        "    model: nn.Module, \n",
        "    train_df: pd.DataFrame, \n",
        "    valid_df: pd.DataFrame, \n",
        "    y_valid: np.ndarray, \n",
        "    n_epochs=30) -> np.ndarray:\n",
        "    - train(\n",
        "    model: nn.Module,\n",
        "    optimizer: Optimizer,\n",
        "    train_loader: data.DataLoader\n",
        ") -> pd.Series:\n",
        "    - valid(\n",
        "    model: nn.Module, \n",
        "    y_valid: np.ndarray, \n",
        "    valid_loader: data.DataLoader\n",
        ") -> pd.Series:\n",
        "      -  predict(model: nn.Module, loader: data.DataLoader) -> np.ndarray:\n",
        "      - calculate_metrics(y_true, y_pred)\n",
        "  \n",
        "5. testデータで推論する\n",
        "  -  run_test_predict(model)\n",
        "    - predict(model: nn.Module, loader: data.DataLoader) -> np.ndarray:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1NldeImSE5I"
      },
      "source": [
        "### データセットを読み込むclass(AtmaDataset)\n",
        "- 1枚ずつ読み込み処理をするのは大変\n",
        "- `torch.utils.data.DataSet`の活用(継承)\n",
        "- `to_dict(orient=\"index\")`で行をキーとして値をvalueにした辞書\n",
        "-  [to_dictについて](https://note.nkmk.me/python-pandas-to-dict/)\n",
        "\n",
        "- `__getitem__`ではindexのintを引数にとって、その時のデータを返す\n",
        "- 画像へのパスとラベルを暗記"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr1lE7My3VxT"
      },
      "source": [
        "from torch.utils import data\n",
        "\n",
        "IMG_MEAN = [0.485, 0.456, 0.406]\n",
        "IMG_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "class AtmaDataset(data.Dataset):\n",
        "    \"\"\"atmaCup用にデータ読み込み等を行なうデータ・セット\"\"\"\n",
        "    object_path_key = \"object_path\"\n",
        "    label_key = \"target\"\n",
        "\n",
        "    @property\n",
        "    def meta_keys(self):\n",
        "        retval = [self.object_path_key]\n",
        "\n",
        "        if self.is_train:\n",
        "            retval += [self.label_key]\n",
        "\n",
        "        return retval\n",
        "\n",
        "    def __init__(self, meta_df: pd.DataFrame, is_train=True):\n",
        "        \"\"\"\n",
        "        args:\n",
        "            meta_df: \n",
        "                画像へのパスと label 情報が含まれている dataframe\n",
        "                必ず object_path に画像へのパス, target に正解ラベルが入っている必要があります\n",
        "\n",
        "            is_train:\n",
        "                True のとき学習用のデータ拡張を適用します.\n",
        "                False の時は単に size にリサイズを行います\n",
        "        \"\"\"\n",
        "\n",
        "        self.is_train = is_train\n",
        "        for k in self.meta_keys:\n",
        "            if k not in meta_df:\n",
        "                raise ValueError(\"meta df must have {}\".format(k))\n",
        "\n",
        "        self.meta_df = meta_df.reset_index(drop=True)\n",
        "        self.index_to_data = self.meta_df.to_dict(orient=\"index\")\n",
        "\n",
        "        size = (224, 224)\n",
        "\n",
        "        additional_items = (\n",
        "            [T.Resize(size)]\n",
        "            if not is_train\n",
        "            else [\n",
        "                T.RandomGrayscale(p=0.2),\n",
        "                #ランダムに上下反転を行う\n",
        "                T.RandomVerticalFlip(),\n",
        "                T.RandomHorizontalFlip(),\n",
        "                #ランダムに明るさ、コントラスト、彩度、色相を変化させる\n",
        "                T.ColorJitter(\n",
        "                    brightness=0.3,\n",
        "                    contrast=0.5,\n",
        "                    saturation=[0.8, 1.3],\n",
        "                    hue=[-0.05, 0.05],\n",
        "                ),\n",
        "                #ランダムにリサイズ及び切り抜きを行う\n",
        "                T.RandomResizedCrop(size),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.transformer = T.Compose(\n",
        "            [*additional_items, T.ToTensor(), T.Normalize(mean=IMG_MEAN, std=IMG_STD)]\n",
        "        )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\t\t\t\t#index_to_dataは辞書型で{行数:{\"target\":value,\"object_id\":value,\"object_path\":value}}\n",
        "        data = self.index_to_data[index]\n",
        "\t\t\t\t#.get(-1)では存在するならvaluesを返し、ないなら-1を返す\n",
        "        obj_path, label = data.get(self.object_path_key), data.get(self.label_key, -1)\n",
        "        img = Image.open(obj_path)\n",
        "        img = self.transformer(img)\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.meta_df)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL28yLExO5Fy"
      },
      "source": [
        "train_meta_df = train_df[['target', 'object_id']].copy()\n",
        "#to_img_pathはobjectidから画像のpathを出力できる関数で、それを列全てに実行\n",
        "train_meta_df['object_path'] = train_meta_df['object_id'].map(to_img_path)\n",
        "\n",
        "dataset = AtmaDataset(meta_df=train_meta_df)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4WhaTeCc6KC",
        "outputId": "4079a29c-ca22-4ce8-d18c-9f3b154d43e9"
      },
      "source": [
        "loader = data.DataLoader(dataset=dataset, batch_size=54, num_workers=4)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxMJ2Qttef9v",
        "outputId": "c07e0baa-ae22-47d0-a787-3837afd40c22"
      },
      "source": [
        "#x_tensorとyはともにtensor型\n",
        "for x_tensor, y in loader:\n",
        "    break"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL-IxG7UfhHT"
      },
      "source": [
        "バッチサイズが54のミニパッチ化され、imgとlabelがミニバッチが一塊としてloaderに入っている"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_LyGH1ffb4T",
        "outputId": "52a28df1-7b42-4e13-f2f3-7e21b42e0abd"
      },
      "source": [
        "x_tensor.shape, y.shape"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([54, 3, 224, 224]), torch.Size([54]))"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du5QPG5Lcwiq"
      },
      "source": [
        "### GPU環境に合わせる\n",
        "- GPUの使用ではモデル、変数、計算に関わるものすべてを .to(device) しなければならない"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSwXZUNsS5oH"
      },
      "source": [
        "assert torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7VeKZhofLKk"
      },
      "source": [
        "### 学習の関数 : train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rcK7V4AfKTE"
      },
      "source": [
        "def train(\n",
        "    model: nn.Module,\n",
        "    optimizer: Optimizer,\n",
        "    train_loader: data.DataLoader\n",
        ") -> pd.Series:\n",
        "\n",
        "    # train にすることでmodel内の学習時にのみ有効な機構が有効になります \n",
        "    model.train()#学習\n",
        "\n",
        "    criterion = nn.MSELoss()#評価関数\n",
        "\n",
        "    for i, (x_i, y_i) in enumerate(train_loader):\n",
        "        x_i = x_i.to(DEVICE)\n",
        "        y_i = y_i.to(DEVICE).reshape(-1, 1).float()\n",
        "\n",
        "        output = model(x_i)#モデルに学習データを入れる\n",
        "        loss = criterion(output, y_i)#学習した値と目的変数のlossを計算　lossはtensorオブジェクト\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()#勾配の初期化\n",
        "        loss.backward()#勾配計算\n",
        "        optimizer.step()#パラメータの微小移動"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBFGKmGx3efq",
        "outputId": "94c29018-fc93-4304-d44a-381047c2d022"
      },
      "source": [
        "inputs = torch.randn(10, 32)\n",
        "targets = torch.randn(10)\n",
        "targets = targets.view(1, -1)\n",
        "targets.float()\n",
        "np.array(y.numpy()).reshape(-1)\n",
        "np.ones((3,4)).reshape(-1)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah0TLrotfWws"
      },
      "source": [
        "### 予測の関数 : predict\n",
        "- [Pytorch tensor と numpy ndarray の変換 ](https://tzmi.hatenablog.com/entry/2020/02/16/170928)\n",
        "- 予測値の配列をndarrayで返す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRymH3HyfSiE"
      },
      "source": [
        "def predict(model: nn.Module, loader: data.DataLoader) -> np.ndarray:\n",
        "    # train とは逆で model 内の学習時にのみ有効な機構がオフになります (Dropouts Layers、BatchNorm Layers...)\n",
        "    model.eval()#推測\n",
        "\n",
        "    predicts = []\n",
        "\n",
        "    for x_i, y_i in loader:\n",
        "\n",
        "        # 明示的に勾配を計算しないように指定することができます. \n",
        "        # この関数ではモデルの更新はせずに単に出力だけを使いますので勾配は不要です.\n",
        "        with torch.no_grad():#勾配を計算しない\n",
        "            output = model(x_i.to(DEVICE))#モデルに入れて推論\n",
        "\n",
        "        #リストの末尾に別のリストやタプルを結合\n",
        "        predicts.extend(output.data.cpu().numpy())#Tensor型からarrayに\n",
        "\n",
        "    pred = np.array(predicts).reshape(-1)#1列になる\n",
        "    return pred"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_vC93FOv0nY"
      },
      "source": [
        "### 予測値の評価指標をする関数(caluculate_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFMkuxYEgbSB"
      },
      "source": [
        "def calculate_metrics(y_true, y_pred) -> dict:\n",
        "    \"\"\"正解ラベルと予測ラベルから指標を計算する\"\"\"    \n",
        "    return {\n",
        "        'rmse': mean_squared_error(y_true, y_pred) ** .5\n",
        "    }\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6KKbTx0wG5R"
      },
      "source": [
        "### 検証データを推論して、評価指標を計算する(valid)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW__UfO-ghFA"
      },
      "source": [
        "def valid(\n",
        "    model: nn.Module, \n",
        "    y_valid: np.ndarray, \n",
        "    valid_loader: data.DataLoader\n",
        ") -> pd.Series:\n",
        "    \"\"\"検証フェーズ\n",
        "    与えられたモデル・データローダを使って検証フェーズを実行。スコアの dict と予測した値を返す\n",
        "    \"\"\"\n",
        "\t\t#predictのデータ\n",
        "    pred = predict(model, valid_loader)\n",
        "\t\t#rmseを求める\n",
        "    score = calculate_metrics(y_valid, pred)#正解ラベルと予測ラベルから指標を計算\n",
        "    return score, pred"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLfvahlkwnVA"
      },
      "source": [
        "### 学習データから学習して検証データに対する評価指標を計算する関数(run_fold)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS98-dRBglsf"
      },
      "source": [
        "def run_fold(\n",
        "    model: nn.Module, \n",
        "    train_df: pd.DataFrame, \n",
        "    valid_df: pd.DataFrame, \n",
        "    y_valid: np.ndarray, \n",
        "    n_epochs=30) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    train / valid に分割されたデータで学習と同時に検証を行なう\n",
        "    \"\"\"\n",
        "\n",
        "    # 0: \n",
        "    #   : 前準備. dataframe から data loader を作成\n",
        "\t\t#データのidを画像へのパスに変換、かつtensor型に変換\n",
        "    train_dataset = AtmaDataset(meta_df=train_df)\n",
        "\t\t#データをミニパッチ化する\n",
        "    train_loader = data.DataLoader(\n",
        "        train_dataset, batch_size=64, shuffle=True, drop_last=True, num_workers=4\n",
        "    )\n",
        "\n",
        "    #  : 検証用の方は is_train=False にしてデータ拡張オフにする\n",
        "    valid_dataset = AtmaDataset(meta_df=valid_df, is_train=False)\n",
        "    valid_loader = data.DataLoader(valid_dataset, batch_size=256, num_workers=4)\n",
        "\n",
        "    # optimizer の定義　\n",
        "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        print(f'start {epoch}')\n",
        "\n",
        "        # 1: 学習用データで学習を実行。学習時のロスを取得\n",
        "        train(model, optimizer, train_loader)\n",
        "\n",
        "        # 2: 検証データでのスコアを計算\n",
        "        score_valid, y_valid_pred = valid(model=model, valid_loader=valid_loader, y_valid=y_valid)\n",
        "\n",
        "        print(score_valid)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx-hUicMxonN"
      },
      "source": [
        "### モデル作成の関数とtrain_meta_dataを作成する関数(create_model create_metadata)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9cf_L6mgurA"
      },
      "source": [
        "def create_model():\n",
        "    model = resnet34(pretrained=False)#事前学習なし\n",
        "    model.fc = nn.Linear(in_features=512, out_features=1, bias=True)    \n",
        "    return model\n",
        "\n",
        "def create_metadata(input_df):\n",
        "    out_df = input_df[['object_id']].copy()\n",
        "    out_df['object_path'] = input_df['object_id'].map(to_img_path)\n",
        "\t\t\n",
        "\t\t#input_dfのcloumnにtarget列があるなら\n",
        "    if \"target\" in input_df:\n",
        "        out_df[\"target\"] = input_df[\"target\"]\n",
        "    return out_df"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFcZJWRsyKZ-"
      },
      "source": [
        "### テストデータに対して推論する関数(run_test_predict)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF6-vjl-g2Ce"
      },
      "source": [
        "def run_test_predict(model):\n",
        "    test_meta_df = create_metadata(test_df)\n",
        "\n",
        "    # 学習時のデータ拡張はオフにしたいので is_train=False としている\n",
        "    test_dataset = AtmaDataset(meta_df=test_meta_df, is_train=False)\n",
        "    test_loader = data.DataLoader(dataset=test_dataset, batch_size=128, drop_last=False, num_workers=4)\n",
        "\n",
        "    y_pred = predict(model, loader=test_loader)\n",
        "    return y_pred"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZk2JYuvhkHf"
      },
      "source": [
        "train_meta_df = create_metadata(train_df)\n",
        "\n",
        "#テストデータの予測値を入れとく配列\n",
        "test_predictions = []\n",
        "\n",
        "fold = KFold(n_splits=5, shuffle=True, random_state=510)\n",
        "#[([1,3,5],[2,4]),(),(),(),()]\n",
        "cv = list(fold.split(X=train_df, y=train_df['target']))\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6kmwzohppN",
        "outputId": "84e639ce-b61d-4306-ab6e-ae572ece5cef"
      },
      "source": [
        "cv = list(fold.split(X=train_df))\n",
        "len(cv)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng2etfrByV6m"
      },
      "source": [
        "### 処理全体を表すコード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW14GIjFhCi4",
        "outputId": "c3ae7bcf-c8c8-46e1-c204-7d80688426ed"
      },
      "source": [
        "train_meta_df = create_metadata(train_df)\n",
        "\n",
        "#テストデータの予測値を入れとく配列\n",
        "test_predictions = []\n",
        "\n",
        "fold = KFold(n_splits=5, shuffle=True, random_state=510)\n",
        "#[([1,3,5],[2,4]),(),(),(),()]\n",
        "cv = list(fold.split(X=train_df))\n",
        "\n",
        "\n",
        "for i, (idx_tr, idx_valid) in enumerate(cv):\n",
        "    model = create_model()\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    # 1. Fold の学習\n",
        "    run_fold(\n",
        "        model=model, \n",
        "        train_df=train_meta_df.iloc[idx_tr], #学習用データ\n",
        "        valid_df=train_meta_df.iloc[idx_valid], #検証データ\n",
        "        y_valid=train_meta_df['target'].values[idx_valid],#検証データのラベル\n",
        "        n_epochs=N_EPOCHS\n",
        "    )\n",
        "\t\t#使いたいのは学習したモデルだけ\n",
        "    # 2. モデルで予測 (本当はローカルに保存した重みを読みだすなどするほうがあとで振り返りやすいが簡易にそのまま予測する)\n",
        "    y_pred_i = run_test_predict(model)#モデルごとに(今回は5個)予測値の塊を配列に追加\n",
        "    test_predictions.append(y_pred_i)\n",
        "    del model"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rmse': 0.9790975492940155}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start 1\n",
            "{'rmse': 0.967776115561879}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start 1\n",
            "{'rmse': 1.065623093229636}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start 1\n",
            "{'rmse': 1.0214558382801135}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start 1\n",
            "{'rmse': 0.997500093430277}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig346C00ydpb"
      },
      "source": [
        "### cvごとに作成したモデル(n_split)による予測値の平均を計算し結果として出力"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTLwFRsImfnb"
      },
      "source": [
        "pred_mean=np.average(test_predictions,axis=0)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "7jPlW8YomJO8",
        "outputId": "c7c7fe15-e291-42a0-d0f8-43fd1aafed46"
      },
      "source": [
        "pd.DataFrame({\"target\":pred_mean})"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.819890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.635594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.606271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.592294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.541709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5914</th>\n",
              "      <td>1.618858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5915</th>\n",
              "      <td>1.459834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5916</th>\n",
              "      <td>1.577902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5917</th>\n",
              "      <td>1.571699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5918</th>\n",
              "      <td>1.560937</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5919 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        target\n",
              "0     1.819890\n",
              "1     1.635594\n",
              "2     1.606271\n",
              "3     1.592294\n",
              "4     1.541709\n",
              "...        ...\n",
              "5914  1.618858\n",
              "5915  1.459834\n",
              "5916  1.577902\n",
              "5917  1.571699\n",
              "5918  1.560937\n",
              "\n",
              "[5919 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    }
  ]
}